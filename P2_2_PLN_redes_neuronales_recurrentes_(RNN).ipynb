{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2_2_PLN_redes neuronales recurrentes (RNN).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZpSFAF22J1dOwxDM7BiO3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavoAdolfoGuizaWalteros/Deep_Learning/blob/main/P2_2_PLN_redes_neuronales_recurrentes_(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qDGg7xnpNjp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876aa3ce-b244-4751-d8ba-c4079fa480c4"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (489.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 489.6 MB 22 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.22.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.37.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.13.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.42.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (12.0.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.7.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow-gpu) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCN8ObZ6pgxE"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import sys"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1qNsB_upmTS",
        "outputId": "4ad5f801-53ae-4553-f136-fcbc6bef2b63"
      },
      "source": [
        "print(\"Version: \", tf.__version__)\n",
        "#print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"GPU esta\", \"disponible\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
        "print(\"Dispositivos disponibles: \", tf.config.list_physical_devices())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Version:  2.7.0\n",
            "GPU esta NOT AVAILABLE\n",
            "Dispositivos disponibles:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGqPpXzup3sN",
        "outputId": "116edc8b-ef18-43b1-e34c-881c6ab84d20"
      },
      "source": [
        "#tf.device('/gpu:0') #activando la CPU\n",
        "tf.device('/GPU:0') #activando la GPU "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.context._EagerDeviceContext at 0x7f4539945780>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAwX5g-gp6tF",
        "outputId": "0ad576be-1450-40e4-f54d-236c06063972",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fileDL= tf.keras.utils.get_file('ElGatoConBotas.txt','https://raw.githubusercontent.com/GustavoAdolfoGuizaWalteros/Deep_Learning/main/Cuentos_txt/ElGatoConBotas.txt')\n",
        "texto = open(fileDL, 'rb').read().decode(encoding='utf-8')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/GustavoAdolfoGuizaWalteros/Deep_Learning/main/Cuentos_txt/ElGatoConBotas.txt\n",
            "\r16384/7808 [==============================================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cCTZ3BYqEF3",
        "outputId": "e3a2780c-004c-4e12-d97e-53e3dbd5c523"
      },
      "source": [
        "import re\n",
        "from unicodedata import normalize\n",
        "#pasa todo a minuscula\n",
        "texto     = texto.lower()\n",
        "#reemplazar tildes por letras similares sin tildes\n",
        "transfor  = dict.fromkeys(map(ord, u'\\u0301\\u0308'), None)\n",
        "texto     = normalize('NFKC', normalize('NFKD', texto).translate(transfor))\n",
        "#quitar saltos de linea\n",
        "texto      = texto.strip()\n",
        "texto      = re.sub('\\r|\\n', ' ',texto)\n",
        "#quitar espacios dobles\n",
        "texto      = re.sub(' +', ' ', texto)\n",
        "#quitando caracteres especiales\n",
        "texto = re.sub(r\"[^a-zA-Z0-9]+\",\" \",texto)\n",
        "print(texto)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato el reparto fue bien simple ya que no se necesito llamar ni al abogado ni al notario pueshabrian consumido por el cobro todo el pobre patrimonioel mayor recibio el molino el segundo se quedo con el burro y al menor le toco solo elgato este se lamentaba de su misera herencia fdlis hermanos decia podran ganarse la vida convenientemente trabajando juntos lo que es yo despues de comerme a mi gato y de hacerme un manguito con su piel me morirede hambre el gato que escuchaba estas palabras pero se hacia el desentendido le dijo en tono serio y pausado no debes afligirte mi senor solo tienes que proporcionarme una bolsa y un par de botaspara andar por entre los matorrales y veras que tu herencia no es tan pobre como piensas aunque el amo del gato no abrigaba sobre esto grandes ilusiones aunque le habiavisto dar tantas muestras de agilidad para cazar ratas y ratones colgarse de los pies esconderse en la harina para hacerse el muerto que no desespero de verse socorrido porel en su miseria cuando el gato tuvo lo que habia pedido se calzo las botas y echandose la bosa tras el cuellosujeto los cordones de esta con las dospatas delanteras y se dirigio a un campo donde habia muchos conejos se puso a recoger hierbas las metio en su saco y se tendio en el suelo como si estuvieramuerto aguardo a que algun conejillo poco conocedor aun de las astucias de estemundo viniera a meter su hocico en la bolsa para comer lo que habia dentro apenas sehabia recostado cuando vio un atolondrado conejillo que se metia en el saco y elmaestro gato tirando los cordones lo encerro y lo mato sin misericordia muy ufano con su presa fue al palacio del rey ypidio hablar con el lo hicieron subir a los aposentos de su majestad dondeal entrar hizo una gran reverencia ante el rey y le dijo he aqui majestad un conejo de campo que el senor marques de carabas era el nombreque invento para su amo me ha encargado obsequiarle de su parte oile a tu amo respondio el rey que le doy las gracias y que me agrada mucho en otra ocasion se oculto en un trigal dejando siempre su saco abierto y cuando en el entrarondos perdices tiro los cordones y las cazo fue en seguida a ofrendarlas al rey tal como habia hecho conel conejo de campo el reyrecibio con agrado las dos perdices yordeno quele diesen de beber el gato continuo durante dos o tres meses llevando al rey obsequios de parte de su amo un dia supo que el rey iria a pasear a orillas del rio con su hija la mas hermosaprincesa del mundo y le dijo a su amo sigues mi consejo tu fortuna estaraasegurada tienes que banarte en el rio en el sitio que te mostrare y en seguidayo hare lo demas el marques de carabas hizo lo quesu gato le aconsejo sin saber de que serviria mientras se estaba banando el rey paso por ahi y el gato se puso a gritar con todas susfuerzas socorro socorro el senor marques de carabas se esta ahogandoa oir el grito el rey asomo la cabezala portezuela y reconociendo al gatoque tantas veces le habia llevado obsequios ordeno a sus guardias que acudieranrapidamente a socorrer al marques de carabas mientras sacaban del rio al pobre marques el gato se acerco a la carroza y le dijoal rey que cuando su amo se estaba banando unos ladrones se ilevaron sus ropas a pesar deque el al ver los grito con todas sus fuerzas auxilio ladrones auxilio e picaro del gato las habia escondido debajo de una enorme piedra el rey ordeno de inmediato a los encargados de su guardarropa que fuesen en busca de susmas bellas vestiduras para el senor marques de caraba el rey le hizo mil atenciones y como el hermoso traje que le acababan de dar realzabasu figura ya que era apuesto y bien formado la hija del rey lo encontro desu agrado basto que el marques de carabas le dirigiera dos o tres miradas sumamenterespetuosas y algo tiernas y ella quedo locamente enamorada el rey quiso que subiera a su carroza y lo acompanara en el paseo el gatoencantado al ver que su proyecto empezaba a resultar se adelanto y habiendoencontrado a unos campesinos que segaban un prado les dijo buenos segadores si no dicen al rey que el prado que estan segando es delmarques de carabas los hare picadillo como carne de budin cuando el rey pregunto a los segadores de quien era ese prado que estaban segando es del senor marques de carabas dijeron a una sola voz puesto que la amenaza del gato los habia asustado tienes aqui una hermosa herencia dijo el rey al marques de carabasvera majestad es una tierra que no deja de producir con abundancia cada ano el maestro gato que iba siempre delante encontro a unos campesinos quecosechaban y les dijobuena gente que estan cosechando si no dicen que todos estos campos pertenecen al marquesde carabas os hare picadillo como carne de budin el rey que paso momentos despues quiso saber a quien pertenecian los campos que veia con del senor marques de carabas contestaron los campesinos y el rey nuevamente se alegrocon el marques el gato que iba delante de la carroza decia siempre lo mismo a todos cuantosencontraba y el rey estaba muy asombrado con las riquezas del senor marques de carabas el maestro gato llego finalmente ante un hermoso castillo cuyo dueno era un ogro el masrico que jamas se hubiera visto pues todas las tierras por donde habian pasado erandependientes de este castillo el gato que tuvo la precaucion de informarse acerca de quien era este ogro y de loque sabia hacer pidio hablar con el diciendo que no habia querido pasar tan cerca de sucastillo sin tener el honor de hacerle la reverencia el ogro lo recibio en la forma mascortes que puede hacerlo un ogro y lo invito a descansar fdle han asegurado dijo el gato que tienes el don de convertirte en cualquier clase de animalque puedes por ejemplo transformarte en leon en elefante cierto respondio el ogro con brusquedad y para demostrartelo veras como me conviertoen leon el gato se asusto tanto al ver a un leon delante de el que en un santiamen setrepo a las canaletas no sin pena ni riesgo a causa de las botas que nada servianpara andar por las tejas agun rato despues viendo que el ogro habia recuperado su forma primitiva el gatobajo y confeso que habia tenido mucho miedo ademas me han asegurado dijo el gato pero no puedo creerlo que tambien tienes el poderde adquirir la forma del mas pequeno animalillo por ejemplo que puedes convertirte en unraton en una rata te confieso que eso me parece imposible imposible repuso el ogro ya veras y al mismo tiempo enque dijoeso se transformo en una rata que se puso a correr por el piso apenas la vio el gato se echo encima de ella y sela comio entretanto el rey que al pasar vio el hermoso castillo del ogro quiso entrar el gato al oir el ruido del carruaje que atravesaba el puente levadizo corrio y ledijo al rey vuestra majestad sea bienvenida al castillo del senor marques de carabas gumo senor marques exclamo el rey este castillotambien os pertenecenada hay mas bello que este patio y todos estos edificios que lo rodean veamos el interior por favor el marques ofrecio la mano a la joven princesa y siguiendo al rey que iba primero entrarona una gran sala donde encontraron una magnifica colacion que el ogro habia mandadopreparar para sus amigos que vendrian a verlo ese mismo dia los cuales no se habianatrevido a entrar sabiendo que el rey estaba alli el rey encantado con las buenas cualidades del senor marques de carabas al igual que su hija queya estaba ioca de amor viendo los valiosos bienes que poseia le dijo despues dehaber bebido cinco o seis copas solo dependera de ti senor marques que seasmi yerno el marques haciendo grandes reverencias acepto el honor que le hacia el rey yese mismo dia se caso con la princesa el gato se convirtio en gran senor y ya no corrio tras las ratas sino para divertirse fin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSFaoozOqHPW",
        "outputId": "f7c55d1c-d7a3-47fe-f72b-7d40c670e329"
      },
      "source": [
        "print('el texto tiene longitud de:{} caracteres'. format(len(texto)))\n",
        "vocab = sorted(set(texto))\n",
        "print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n",
        "print(vocab)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el texto tiene longitud de:7808 caracteres\n",
            "el texto esta compuesto de estos :25 caracteres\n",
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNlMpghHqStT",
        "outputId": "aa86a676-727c-478b-adc8-3d0e0bc056bd"
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)} # asignamos un número a cada vocablo\n",
        "idx2char = np.array(vocab)\n",
        "#-----------revisando las conversiones\n",
        "#for char,_ in zip(char2idx, range(len(vocab))):\n",
        "#    print(' {:4s}: {:3d},'.format(repr(char),char2idx[char]))\n",
        "\n",
        "#pasamos todo el texto a números\n",
        "texto_como_entero= np.array([char2idx[c] for c in texto])\n",
        "print('texto: {}'.format(repr(texto[:100])))\n",
        "print('{}'.format(repr(texto_como_entero[:100])))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texto: 'el gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato'\n",
            "array([ 5, 11,  0,  7,  1, 19, 14,  0,  3, 14, 13,  0,  2, 14, 19,  1, 18,\n",
            "        0, 20, 13,  0, 12, 14, 11,  9, 13,  5, 17, 14,  0,  4,  5, 10, 14,\n",
            "        0,  3, 14, 12, 14,  0, 20, 13,  9,  3,  1,  0,  8,  5, 17,  5, 13,\n",
            "        3,  9,  1,  0,  1,  0, 18, 20, 18,  0, 19, 17,  5, 18,  0,  8,  9,\n",
            "       10, 14, 18,  0, 18, 20,  0, 12, 14, 11,  9, 13, 14,  0, 18, 20,  0,\n",
            "        2, 20, 17, 17, 14,  0, 23,  0, 18, 20,  0,  7,  1, 19, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQEsOP-1oRzk",
        "outputId": "bfb0cb43-aaf1-4857-f296-4928c76a9ae0"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "array_total = np.asarray([idx2char,texto_como_entero])\n",
        "\n",
        "np.savetxt('sample.csv', array_total,fmt=\"%s\", delimiter=\",\")\n",
        "\n",
        "# Vocables to CSV\n",
        "np.savetxt('vocables.csv', idx2char, fmt=\"%c\", delimiter=\",\")\n",
        "\n",
        "# Matriz Numerica to CSV\n",
        "np.savetxt('matriz_numeros.csv', texto_como_entero,fmt=\"%s\", delimiter=\",\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7nBCsdAqYYR",
        "outputId": "f6b0c62f-18a0-42ae-fa7d-dc1a6c225fb0"
      },
      "source": [
        "char_dataset= tf.data.Dataset.from_tensor_slices(texto_como_entero)\n",
        "#cantidad de secuencia de caracteres\n",
        "secu_length=150\n",
        "#creamos secuencias de maximo 100 caractereres\n",
        "secuencias= char_dataset.batch(secu_length+1, drop_remainder=True)\n",
        "for item in secuencias.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'el gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato el reparto fue bien simple ya que no se necesito l'\n",
            "'lamar ni al abogado ni al notario pueshabrian consumido por el cobro todo el pobre patrimonioel mayor recibio el molino el segundo se quedo con el burr'\n",
            "'o y al menor le toco solo elgato este se lamentaba de su misera herencia fdlis hermanos decia podran ganarse la vida convenientemente trabajando juntos'\n",
            "' lo que es yo despues de comerme a mi gato y de hacerme un manguito con su piel me morirede hambre el gato que escuchaba estas palabras pero se hacia e'\n",
            "'l desentendido le dijo en tono serio y pausado no debes afligirte mi senor solo tienes que proporcionarme una bolsa y un par de botaspara andar por ent'\n",
            "'re los matorrales y veras que tu herencia no es tan pobre como piensas aunque el amo del gato no abrigaba sobre esto grandes ilusiones aunque le habiav'\n",
            "'isto dar tantas muestras de agilidad para cazar ratas y ratones colgarse de los pies esconderse en la harina para hacerse el muerto que no desespero de'\n",
            "' verse socorrido porel en su miseria cuando el gato tuvo lo que habia pedido se calzo las botas y echandose la bosa tras el cuellosujeto los cordones d'\n",
            "'e esta con las dospatas delanteras y se dirigio a un campo donde habia muchos conejos se puso a recoger hierbas las metio en su saco y se tendio en el '\n",
            "'suelo como si estuvieramuerto aguardo a que algun conejillo poco conocedor aun de las astucias de estemundo viniera a meter su hocico en la bolsa para '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGS_AHDrqZ3B",
        "outputId": "f58694ec-8299-4398-eb69-cebb12bf7a23"
      },
      "source": [
        "#funcion para obtener el conjunto de datos de trainning\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text= chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset  = secuencias.map(split_input_target)\n",
        "#el dataset contiene un conjunto de parejas de secuencia de texto\n",
        "#(con la representación numérica de los caracteres), donde el \n",
        "#primer componente de la pareja contiene un paquete con una secuencia \n",
        "#de 100 caracteres del texto original y la segunda su correspondiente salida, \n",
        "#también de 100 caracteres. )\n",
        "for input_example, target_example in dataset.take(1):\n",
        "  print('input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input data:  'el gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato el reparto fue bien simple ya que no se necesito '\n",
            "Target data:  'l gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato el reparto fue bien simple ya que no se necesito l'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nez2YVdWqfi1",
        "outputId": "e79046a8-cf02-4e8e-c14e-30922871aee3"
      },
      "source": [
        "#imprimimos el tensor del dataset\n",
        "print(dataset)\n",
        "#Hyper-Parametros para entrenamiento  de una rede neuronal \n",
        "#   -los datos se agrupan en batch\n",
        "BATCH_SIZE= 64\n",
        "#    -Tamaño de memoria disponible \n",
        "BUFFER_SIZE=10000\n",
        "dataset= dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print (dataset)\n",
        "#En el tensor dataset disponemos los datos de entrenamiento\n",
        "#con agrupamienttos (batches) compuestos de 64 parejas de secuencias \n",
        "#de 100 integers de 64 bits que representan el carácter correspondiente \n",
        "#en el vocabulario."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MapDataset shapes: ((150,), (150,)), types: (tf.int64, tf.int64)>\n",
            "<BatchDataset shapes: ((64, 150), (64, 150)), types: (tf.int64, tf.int64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgZcxW16qj6b",
        "outputId": "0122d32d-1d09-4f35-8835-e6efd76598c0"
      },
      "source": [
        "#como es un problema de clasificación estándar \n",
        "#para el que debemos definir la función de Lossy el optimizador.\n",
        "def lossy(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "def create_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  #creando el modelo\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                         return_sequences=True,\n",
        "                         stateful=True,\n",
        "                         recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)                               \n",
        "  ])\n",
        "  #En cuanto al optimizador usaremos tf.keras.optimizers.Adam \n",
        "  #con los argumentos por defecto del optimizador Adam. \n",
        "  model.compile(optimizer='adam',\n",
        "              loss=lossy,\n",
        "              metrics=['accuracy'])\n",
        "  return model\n",
        "vocab_size= len(vocab)\n",
        "#dimensiones de los vectores que tendrá la capa.\n",
        "embedding_dim= 256\n",
        "#cantidad de neuronas\n",
        "rnn_units=1024\n",
        "#creamos nuestra red neuronal RNN\n",
        "model=create_model(vocab_size   =vocab_size,\n",
        "                  embedding_dim =embedding_dim,\n",
        "                  rnn_units     =rnn_units,\n",
        "                  batch_size    =BATCH_SIZE)\n",
        "#summary()para visualizar la estructura del modelo\n",
        "model.summary()\n",
        "#resultados=  -La capa LSTM consta más de 5 millones de parametros)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           6400      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 25)            25625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,279,001\n",
            "Trainable params: 5,279,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs0kJ2FGqlDh",
        "outputId": "d640bd6d-5733-4354-e1a9-997ed91cab95"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-0jg1S2qm2Y"
      },
      "source": [
        "checkpoint_dir='/content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/Redes neuronales recurrentes (RNN)/checkpointsV5/'\n",
        "checkpoint_prefix= os.path.join(checkpoint_dir,\"cp_{epoch:04d}.ckpt\")\n",
        "\n",
        "\n",
        "cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                               monitor='loss',\n",
        "                                               verbose=1,\n",
        "                                               save_weights_only=True,\n",
        "                                               save_best_only=True,\n",
        "                                               mode='auto')\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4iq_c47q012",
        "outputId": "8deacf72-b08c-4d6e-ab01-876773d0f22e"
      },
      "source": [
        "EPOCHS=65\n",
        "history=model.fit(dataset, \n",
        "                  epochs=EPOCHS, \n",
        "                  verbose=1,\n",
        "                  callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.3454 - accuracy: 0.1411 \n",
            "Epoch 00001: loss improved from inf to 3.34538, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/Redes neuronales recurrentes (RNN)/checkpointsV4/cp_0001.ckpt\n",
            "16/16 [==============================] - 210s 13s/step - loss: 3.3454 - accuracy: 0.1411\n",
            "Epoch 2/3\n",
            "16/16 [==============================] - ETA: 0s - loss: 3.1199 - accuracy: 0.1693 \n",
            "Epoch 00002: loss improved from 3.34538 to 3.11988, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/Redes neuronales recurrentes (RNN)/checkpointsV4/cp_0002.ckpt\n",
            "16/16 [==============================] - 205s 13s/step - loss: 3.1199 - accuracy: 0.1693\n",
            "Epoch 3/3\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.9551 - accuracy: 0.2019 \n",
            "Epoch 00003: loss improved from 3.11988 to 2.95511, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/Redes neuronales recurrentes (RNN)/checkpointsV4/cp_0003.ckpt\n",
            "16/16 [==============================] - 206s 13s/step - loss: 2.9551 - accuracy: 0.2019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwDKZMorsebn",
        "outputId": "230cff41-d9c5-4d7c-acca-aeefb2718830"
      },
      "source": [
        "#creamos un modelo con iguales caracteristicas al 1° modelo\n",
        "model=create_model(vocab_size   =vocab_size,\n",
        "                  embedding_dim =embedding_dim,\n",
        "                  rnn_units     =rnn_units,\n",
        "                  batch_size    =BATCH_SIZE)\n",
        "\n",
        "#buscamos el ultimo checkpoint de entrenamiento\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(latest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/Redes neuronales recurrentes (RNN)/checkpointsV4/cp_0003.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_q9VrCqsfBV",
        "outputId": "0795ecb6-2633-4ffc-907f-1608a65861f5"
      },
      "source": [
        "# cargamos los pesos al nuevo modelo (estos valores tienes una variación de un 10%)\n",
        "model.load_weights(latest)\n",
        "# continuamos el entrenamiento desde el checkpoint en que quedamos\n",
        "history2=model.fit(dataset, \n",
        "                    epochs=65, \n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.7219 - accuracy: 0.2584 \n",
            "Epoch 00001: loss improved from 2.95511 to 2.72188, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/Redes neuronales recurrentes (RNN)/checkpointsV4/cp_0001.ckpt\n",
            "16/16 [==============================] - 205s 13s/step - loss: 2.7219 - accuracy: 0.2584\n",
            "Epoch 2/3\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.5620 - accuracy: 0.2882 \n",
            "Epoch 00002: loss improved from 2.72188 to 2.56204, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/Redes neuronales recurrentes (RNN)/checkpointsV4/cp_0002.ckpt\n",
            "16/16 [==============================] - 205s 13s/step - loss: 2.5620 - accuracy: 0.2882\n",
            "Epoch 3/3\n",
            "16/16 [==============================] - ETA: 0s - loss: 2.4175 - accuracy: 0.3087 \n",
            "Epoch 00003: loss improved from 2.56204 to 2.41754, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/Redes neuronales recurrentes (RNN)/checkpointsV4/cp_0003.ckpt\n",
            "16/16 [==============================] - 205s 13s/step - loss: 2.4175 - accuracy: 0.3087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hieK7Lnsg6M",
        "outputId": "82a9897c-a944-402a-8421-6eff65ec3b37"
      },
      "source": [
        "# You can change the directory name\n",
        "LOG_DIR = 'tb_logs'\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "import os\n",
        "if not os.path.exists(LOG_DIR):\n",
        "  os.makedirs(LOG_DIR)\n",
        "  \n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 22:17:43--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.161.241.46, 18.205.222.128, 54.237.133.81, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.161.241.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.3’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  3.28MB/s    in 5.0s    \n",
            "\n",
            "2021-11-22 22:17:48 (2.61 MB/s) - ‘ngrok-stable-linux-amd64.zip.3’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n",
            "https://4ea8-34-83-45-70.ngrok.io\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5dPGKHJszeW",
        "outputId": "a0b87f20-c417-414d-b67b-477cc6facd26"
      },
      "source": [
        "tbCallBack = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, \n",
        "                         histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         write_images=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n",
            "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ys4XasKs7-3",
        "outputId": "6f89a518-ddf6-42e4-a96d-2ac9bde3465d"
      },
      "source": [
        "#model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)\n",
        "history_TB=model.fit(dataset, \n",
        "                    epochs=70, \n",
        "                    verbose=1,\n",
        "                    callbacks=[tbCallBack])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "16/16 [==============================] - 210s 13s/step - loss: 2.2857 - accuracy: 0.3378\n",
            "Epoch 2/4\n",
            "16/16 [==============================] - 222s 14s/step - loss: 2.1491 - accuracy: 0.3839\n",
            "Epoch 3/4\n",
            "16/16 [==============================] - 221s 14s/step - loss: 2.0066 - accuracy: 0.4335\n",
            "Epoch 4/4\n",
            "16/16 [==============================] - 223s 14s/step - loss: 1.8304 - accuracy: 0.4950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d07CkqBOtC2r"
      },
      "source": [
        "#creamos un modelo tomando como base el ultimo checkpoint\n",
        "model = create_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJg5icLEtL2q"
      },
      "source": [
        "#funcion para generar texto\n",
        "def generate_text(model, start_string):\n",
        "  #definimos cuantos tensores/cantidad de texto generaremos\n",
        "  num_generate=500\n",
        "  #convertimos el texto en números\n",
        "  input_eval=[char2idx[s] for s in start_string]\n",
        "  input_eval= tf.expand_dims (input_eval,0)\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 0.2  #(0.0 a  1) entre más alta la temperatura más creatividad al modelo, pero tambien más errores ortograficos.\n",
        "  model.reset_states() #bucle para generar caracteres, mediante predicciones\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    input_eval= tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append (idx2char[predicted_id])\n",
        "  \n",
        "  return (start_string+ ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g8e_rWqtNOh",
        "outputId": "a7568750-836e-44c8-9b25-184f352034f1"
      },
      "source": [
        "print(generate_text(model, start_string=u\"un molindero\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "un molindero data lime de de de de cot huot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quot quo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIa83WlttSqD",
        "outputId": "13074c97-b961-4001-de7d-33f62410c906"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "import os\n",
        "dir_export= '/content/gdrive/MyDrive/Colab Notebooks/Modelos'\n",
        "#dir_export= os.path.join(dir_drive)\n",
        "# Serializamos el modelo en forma JSON\n",
        "model_json = model.to_json()\n",
        "with open(os.path.join(dir_export,'RNN_ElGatoConBotas_json.json'), 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(os.path.join(dir_export,'RNN_ElGatoConBotas_pesos.hdf5'))\n",
        "model.save(os.path.join(dir_export,'RNN_ElGatoConBotas_model.h5'))\n",
        "print(\"modelo salvado en Drive de google\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modelo salvado en Drive de google\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mkFQTF8tgFP",
        "outputId": "b46bc41a-64fd-49e3-bb05-8fe86295e7c6"
      },
      "source": [
        "!wget https://github.com/GustavoAdolfoGuizaWalteros/Deep_Learning/blob/main/Modelos/RNN_ElGatoConBotas_pesos.hdf5?raw=true \\\n",
        "      -O RNN_ElGatoConBotas_model.h5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-22 22:51:50--  https://github.com/GustavoAdolfoGuizaWalteros/Deep_Learning/blob/main/Modelos/RNN_ElGatoConBotas_pesos.hdf5?raw=true\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/GustavoAdolfoGuizaWalteros/Deep_Learning/raw/main/Modelos/RNN_ElGatoConBotas_pesos.hdf5 [following]\n",
            "--2021-11-22 22:51:50--  https://github.com/GustavoAdolfoGuizaWalteros/Deep_Learning/raw/main/Modelos/RNN_ElGatoConBotas_pesos.hdf5\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/GustavoAdolfoGuizaWalteros/Deep_Learning/main/Modelos/RNN_ElGatoConBotas_pesos.hdf5 [following]\n",
            "--2021-11-22 22:51:50--  https://raw.githubusercontent.com/GustavoAdolfoGuizaWalteros/Deep_Learning/main/Modelos/RNN_ElGatoConBotas_pesos.hdf5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21195864 (20M) [application/octet-stream]\n",
            "Saving to: ‘RNN_ElGatoConBotas_model.h5’\n",
            "\n",
            "RNN_ElGatoConBotas_ 100%[===================>]  20.21M   125MB/s    in 0.2s    \n",
            "\n",
            "2021-11-22 22:51:51 (125 MB/s) - ‘RNN_ElGatoConBotas_model.h5’ saved [21195864/21195864]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSrWeRZ4yipo",
        "outputId": "c2434395-f655-4f9b-ddf7-c7391718a2a8"
      },
      "source": [
        "!pip install pyprind"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyprind\n",
            "  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: pyprind\n",
            "Successfully installed pyprind-2.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cujq9Sayk6J"
      },
      "source": [
        "def reporthook(count, block_size, total_size):\n",
        "    global start_time\n",
        "    if count == 0:\n",
        "        start_time = time.time()\n",
        "        return\n",
        "    duration = time.time() - start_time\n",
        "    progress_size = int(count * block_size)\n",
        "    speed = progress_size / (1024.**2 * duration)\n",
        "    percent = count * block_size * 100. / total_size\n",
        "    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d segundos transcurrido\" %\n",
        "                    (percent, progress_size / (1024.**2), speed, duration))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "import urllib.request\n",
        "url_github_Model='https://github.com/luisFernandoCastellanosG/Machine_learning/blob/master/DeepLearning/PLN/recurrent_network_RNN/Modelos/RNN_LasMinasDelReySalomon_model.h5?raw=true'\n",
        "urllib.request.urlretrieve(url_github_Model,\n",
        "                           'RNN_ElGatoConBotas_model.h5', \n",
        "                           reporthook)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGuFBILgyl7J"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/gdrive/MyDrive/Colab Notebooks/Modelos/RNN_ElGatoConBotas_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXlxLbtOypBS"
      },
      "source": [
        "print(generate_text(new_model, start_string=u\"los fantasmas de \"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}