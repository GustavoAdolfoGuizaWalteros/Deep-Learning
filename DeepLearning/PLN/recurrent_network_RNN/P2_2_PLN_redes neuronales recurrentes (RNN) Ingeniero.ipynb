{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2_2_PLN_redes neuronales recurrentes (RNN).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k6zNNLvrPR1f",
        "FshwyfFykB_4",
        "SKuJocQwCLg1"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3cNJsmEei2i"
      },
      "source": [
        "#!kill -9 -1 #reiniciando la maquina virtual"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul9CHmeeRwy1",
        "outputId": "d280e1e4-d487-47f3-ce22-9f58457de672"
      },
      "source": [
        "#!pip list\n",
        "!nvcc --version  #Version de CUDA en la maquina virtual"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGa1tvf5t5r4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import timeit               #para medir tiempos\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "import time\n",
        "import sys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXlRSrBJrK9T",
        "outputId": "8a05107b-7894-4ef2-97d8-9046d6f81da4"
      },
      "source": [
        "print(\"Tensorflow Version: \", tf.__version__)\n",
        "print(\"Dispositivos disponibles para entrenar: \", tf.config.list_physical_devices())\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Encontrada la GPU: {}'.format(device_name))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow Version:  2.7.0\n",
            "Dispositivos disponibles para entrenar:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "Encontrada la GPU: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8hkb1wlQKET"
      },
      "source": [
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)   "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsqDzp_4Q0nV",
        "outputId": "de529b05-1240-443d-dfea-ce0ec072b60f"
      },
      "source": [
        "cpu()  #ejecutamos entrenamiento con CPU\n",
        "gpu()  #ejecutamos entrenamiento con GPU\n",
        "# Run the op several times.\n",
        "print('TIEMPO (seg) para entrenar una red convolucional de 32x7x7x3 filtros sobre un randomico de 100x100x100x3 imagenes '\n",
        "      '(batch x height x width x channel). suma de 10 epochs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIEMPO (seg) para entrenar una red convolucional de 32x7x7x3 filtros sobre un randomico de 100x100x100x3 imagenes (batch x height x width x channel). suma de 10 epochs.\n",
            "CPU (s):\n",
            "3.7016485500007548\n",
            "GPU (s):\n",
            "0.054879336999874795\n",
            "GPU speedup over CPU: 67x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9E2ihO2rLjM",
        "outputId": "51c6b499-6aa2-4e91-a84e-913f7d0e7ea1"
      },
      "source": [
        "#tf.device('/gpu:0') #activando la CPU\n",
        "tf.device('/device:GPU:0') #activando la GPU "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.eager.context._EagerDeviceContext at 0x7fb9a62b2a00>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PETkDFl3Mff",
        "outputId": "441acbb2-76a0-43ff-80fe-93be0606c3ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "fileDL= tf.keras.utils.get_file('ElGatoConBotas.txt','https://raw.githubusercontent.com/GustavoAdolfoGuizaWalteros/Deep_Learning/main/Cuentos_txt/ElGatoConBotas.txt')\n",
        "texto = open(fileDL, 'rb').read().decode(encoding='utf-8')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/GustavoAdolfoGuizaWalteros/Deep_Learning/main/Cuentos_txt/ElGatoConBotas.txt\n",
            "\r16384/7808 [==============================================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SbnxWwxfNnH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9ed368-db60-4115-da0a-1821ccc61283"
      },
      "source": [
        "import re\n",
        "from unicodedata import normalize\n",
        "#pasa todo a minuscula\n",
        "texto     = texto.lower()\n",
        "#reemplazar tildes por letras similares sin tildes\n",
        "transfor  = dict.fromkeys(map(ord, u'\\u0301\\u0308'), None)\n",
        "texto     = normalize('NFKC', normalize('NFKD', texto).translate(transfor))\n",
        "#quitar saltos de linea\n",
        "texto      = texto.strip()\n",
        "texto      = re.sub('\\r|\\n', ' ',texto)\n",
        "#quitar espacios dobles\n",
        "texto      = re.sub(' +', ' ', texto)\n",
        "#quitando caracteres especiales\n",
        "texto = re.sub(r\"[^a-zA-Z0-9]+\",\" \",texto)\n",
        "print(texto)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato el reparto fue bien simple ya que no se necesito llamar ni al abogado ni al notario pueshabrian consumido por el cobro todo el pobre patrimonioel mayor recibio el molino el segundo se quedo con el burro y al menor le toco solo elgato este se lamentaba de su misera herencia fdlis hermanos decia podran ganarse la vida convenientemente trabajando juntos lo que es yo despues de comerme a mi gato y de hacerme un manguito con su piel me morirede hambre el gato que escuchaba estas palabras pero se hacia el desentendido le dijo en tono serio y pausado no debes afligirte mi senor solo tienes que proporcionarme una bolsa y un par de botaspara andar por entre los matorrales y veras que tu herencia no es tan pobre como piensas aunque el amo del gato no abrigaba sobre esto grandes ilusiones aunque le habiavisto dar tantas muestras de agilidad para cazar ratas y ratones colgarse de los pies esconderse en la harina para hacerse el muerto que no desespero de verse socorrido porel en su miseria cuando el gato tuvo lo que habia pedido se calzo las botas y echandose la bosa tras el cuellosujeto los cordones de esta con las dospatas delanteras y se dirigio a un campo donde habia muchos conejos se puso a recoger hierbas las metio en su saco y se tendio en el suelo como si estuvieramuerto aguardo a que algun conejillo poco conocedor aun de las astucias de estemundo viniera a meter su hocico en la bolsa para comer lo que habia dentro apenas sehabia recostado cuando vio un atolondrado conejillo que se metia en el saco y elmaestro gato tirando los cordones lo encerro y lo mato sin misericordia muy ufano con su presa fue al palacio del rey ypidio hablar con el lo hicieron subir a los aposentos de su majestad dondeal entrar hizo una gran reverencia ante el rey y le dijo he aqui majestad un conejo de campo que el senor marques de carabas era el nombreque invento para su amo me ha encargado obsequiarle de su parte oile a tu amo respondio el rey que le doy las gracias y que me agrada mucho en otra ocasion se oculto en un trigal dejando siempre su saco abierto y cuando en el entrarondos perdices tiro los cordones y las cazo fue en seguida a ofrendarlas al rey tal como habia hecho conel conejo de campo el reyrecibio con agrado las dos perdices yordeno quele diesen de beber el gato continuo durante dos o tres meses llevando al rey obsequios de parte de su amo un dia supo que el rey iria a pasear a orillas del rio con su hija la mas hermosaprincesa del mundo y le dijo a su amo sigues mi consejo tu fortuna estaraasegurada tienes que banarte en el rio en el sitio que te mostrare y en seguidayo hare lo demas el marques de carabas hizo lo quesu gato le aconsejo sin saber de que serviria mientras se estaba banando el rey paso por ahi y el gato se puso a gritar con todas susfuerzas socorro socorro el senor marques de carabas se esta ahogandoa oir el grito el rey asomo la cabezala portezuela y reconociendo al gatoque tantas veces le habia llevado obsequios ordeno a sus guardias que acudieranrapidamente a socorrer al marques de carabas mientras sacaban del rio al pobre marques el gato se acerco a la carroza y le dijoal rey que cuando su amo se estaba banando unos ladrones se ilevaron sus ropas a pesar deque el al ver los grito con todas sus fuerzas auxilio ladrones auxilio e picaro del gato las habia escondido debajo de una enorme piedra el rey ordeno de inmediato a los encargados de su guardarropa que fuesen en busca de susmas bellas vestiduras para el senor marques de caraba el rey le hizo mil atenciones y como el hermoso traje que le acababan de dar realzabasu figura ya que era apuesto y bien formado la hija del rey lo encontro desu agrado basto que el marques de carabas le dirigiera dos o tres miradas sumamenterespetuosas y algo tiernas y ella quedo locamente enamorada el rey quiso que subiera a su carroza y lo acompanara en el paseo el gatoencantado al ver que su proyecto empezaba a resultar se adelanto y habiendoencontrado a unos campesinos que segaban un prado les dijo buenos segadores si no dicen al rey que el prado que estan segando es delmarques de carabas los hare picadillo como carne de budin cuando el rey pregunto a los segadores de quien era ese prado que estaban segando es del senor marques de carabas dijeron a una sola voz puesto que la amenaza del gato los habia asustado tienes aqui una hermosa herencia dijo el rey al marques de carabasvera majestad es una tierra que no deja de producir con abundancia cada ano el maestro gato que iba siempre delante encontro a unos campesinos quecosechaban y les dijobuena gente que estan cosechando si no dicen que todos estos campos pertenecen al marquesde carabas os hare picadillo como carne de budin el rey que paso momentos despues quiso saber a quien pertenecian los campos que veia con del senor marques de carabas contestaron los campesinos y el rey nuevamente se alegrocon el marques el gato que iba delante de la carroza decia siempre lo mismo a todos cuantosencontraba y el rey estaba muy asombrado con las riquezas del senor marques de carabas el maestro gato llego finalmente ante un hermoso castillo cuyo dueno era un ogro el masrico que jamas se hubiera visto pues todas las tierras por donde habian pasado erandependientes de este castillo el gato que tuvo la precaucion de informarse acerca de quien era este ogro y de loque sabia hacer pidio hablar con el diciendo que no habia querido pasar tan cerca de sucastillo sin tener el honor de hacerle la reverencia el ogro lo recibio en la forma mascortes que puede hacerlo un ogro y lo invito a descansar fdle han asegurado dijo el gato que tienes el don de convertirte en cualquier clase de animalque puedes por ejemplo transformarte en leon en elefante cierto respondio el ogro con brusquedad y para demostrartelo veras como me conviertoen leon el gato se asusto tanto al ver a un leon delante de el que en un santiamen setrepo a las canaletas no sin pena ni riesgo a causa de las botas que nada servianpara andar por las tejas agun rato despues viendo que el ogro habia recuperado su forma primitiva el gatobajo y confeso que habia tenido mucho miedo ademas me han asegurado dijo el gato pero no puedo creerlo que tambien tienes el poderde adquirir la forma del mas pequeno animalillo por ejemplo que puedes convertirte en unraton en una rata te confieso que eso me parece imposible imposible repuso el ogro ya veras y al mismo tiempo enque dijoeso se transformo en una rata que se puso a correr por el piso apenas la vio el gato se echo encima de ella y sela comio entretanto el rey que al pasar vio el hermoso castillo del ogro quiso entrar el gato al oir el ruido del carruaje que atravesaba el puente levadizo corrio y ledijo al rey vuestra majestad sea bienvenida al castillo del senor marques de carabas gumo senor marques exclamo el rey este castillotambien os pertenecenada hay mas bello que este patio y todos estos edificios que lo rodean veamos el interior por favor el marques ofrecio la mano a la joven princesa y siguiendo al rey que iba primero entrarona una gran sala donde encontraron una magnifica colacion que el ogro habia mandadopreparar para sus amigos que vendrian a verlo ese mismo dia los cuales no se habianatrevido a entrar sabiendo que el rey estaba alli el rey encantado con las buenas cualidades del senor marques de carabas al igual que su hija queya estaba ioca de amor viendo los valiosos bienes que poseia le dijo despues dehaber bebido cinco o seis copas solo dependera de ti senor marques que seasmi yerno el marques haciendo grandes reverencias acepto el honor que le hacia el rey yese mismo dia se caso con la princesa el gato se convirtio en gran senor y ya no corrio tras las ratas sino para divertirse fin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpxHpVkcys57",
        "outputId": "9bb7aba4-967d-439b-bf67-6f1287ec5a0e"
      },
      "source": [
        "print('el texto tiene longitud de:{} caracteres'. format(len(texto)))\n",
        "vocab = sorted(set(texto))\n",
        "print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n",
        "print(vocab)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el texto tiene longitud de:7808 caracteres\n",
            "el texto esta compuesto de estos :25 caracteres\n",
            "[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUZb1tLVzIke",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d68d3c-aaed-42f0-dfff-2b70297972ae"
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)} # asignamos un número a cada vocablo\n",
        "idx2char = np.array(vocab)\n",
        "#-----------revisando las conversiones\n",
        "\n",
        "#for char,_ in zip(char2idx, range(len(vocab))):\n",
        "    #print(' {:4s}: {:3d},'.format(repr(char),char2idx[char]))\n",
        "\n",
        "#pasamos todo el texto a números\n",
        "texto_como_entero= np.array([char2idx[c] for c in texto])\n",
        "print('texto: {}'.format(repr(texto[:100])))\n",
        "print('{}'.format(repr(texto_como_entero[:100])))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texto: 'el gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato'\n",
            "array([ 5, 11,  0,  7,  1, 19, 14,  0,  3, 14, 13,  0,  2, 14, 19,  1, 18,\n",
            "        0, 20, 13,  0, 12, 14, 11,  9, 13,  5, 17, 14,  0,  4,  5, 10, 14,\n",
            "        0,  3, 14, 12, 14,  0, 20, 13,  9,  3,  1,  0,  8,  5, 17,  5, 13,\n",
            "        3,  9,  1,  0,  1,  0, 18, 20, 18,  0, 19, 17,  5, 18,  0,  8,  9,\n",
            "       10, 14, 18,  0, 18, 20,  0, 12, 14, 11,  9, 13, 14,  0, 18, 20,  0,\n",
            "        2, 20, 17, 17, 14,  0, 23,  0, 18, 20,  0,  7,  1, 19, 14])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl6mkWE6u2iH"
      },
      "source": [
        "rows=[]\n",
        "columns=['num','vocab']\n",
        "for i, voc in enumerate(vocab):\n",
        "  #print(i,'-->', voc)\n",
        "  rows.append([i,voc])\n",
        "df= pd.DataFrame(columns=['num','vocab'],data=rows)\n",
        "df.head(10)\n",
        "df.to_csv('data_vocab.csv',index=False)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky_cT7xN4OiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3438558e-b202-4a09-e46d-7919e79c6098"
      },
      "source": [
        "char_dataset= tf.data.Dataset.from_tensor_slices(texto_como_entero)\n",
        "#cantidad de secuencia de caracteres\n",
        "secu_length=150\n",
        "#creamos secuencias de maximo 100 caractereres\n",
        "secuencias= char_dataset.batch(secu_length+1, drop_remainder=True)\n",
        "for item in secuencias.take(10):\n",
        "  print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'el gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato el reparto fue bien simple ya que no se necesito l'\n",
            "'lamar ni al abogado ni al notario pueshabrian consumido por el cobro todo el pobre patrimonioel mayor recibio el molino el segundo se quedo con el burr'\n",
            "'o y al menor le toco solo elgato este se lamentaba de su misera herencia fdlis hermanos decia podran ganarse la vida convenientemente trabajando juntos'\n",
            "' lo que es yo despues de comerme a mi gato y de hacerme un manguito con su piel me morirede hambre el gato que escuchaba estas palabras pero se hacia e'\n",
            "'l desentendido le dijo en tono serio y pausado no debes afligirte mi senor solo tienes que proporcionarme una bolsa y un par de botaspara andar por ent'\n",
            "'re los matorrales y veras que tu herencia no es tan pobre como piensas aunque el amo del gato no abrigaba sobre esto grandes ilusiones aunque le habiav'\n",
            "'isto dar tantas muestras de agilidad para cazar ratas y ratones colgarse de los pies esconderse en la harina para hacerse el muerto que no desespero de'\n",
            "' verse socorrido porel en su miseria cuando el gato tuvo lo que habia pedido se calzo las botas y echandose la bosa tras el cuellosujeto los cordones d'\n",
            "'e esta con las dospatas delanteras y se dirigio a un campo donde habia muchos conejos se puso a recoger hierbas las metio en su saco y se tendio en el '\n",
            "'suelo como si estuvieramuerto aguardo a que algun conejillo poco conocedor aun de las astucias de estemundo viniera a meter su hocico en la bolsa para '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l6Tobzz7hww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb52938-2e88-4d99-eb61-10f9bef85a10"
      },
      "source": [
        "#funcion para obtener el conjunto de datos de trainning\n",
        "def split_input_target(chunk):\n",
        "  input_text = chunk[:-1]\n",
        "  target_text= chunk[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "dataset  = secuencias.map(split_input_target)\n",
        "#el dataset contiene un conjunto de parejas de secuencia de texto\n",
        "#(con la representación numérica de los caracteres), donde el \n",
        "#primer componente de la pareja contiene un paquete con una secuencia \n",
        "#de 100 caracteres del texto original y la segunda su correspondiente salida, \n",
        "#también de 100 caracteres. )\n",
        "for input_example, target_example in dataset.take(1):\n",
        "  print('input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "  print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input data:  'el gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato el reparto fue bien simple ya que no se necesito '\n",
            "Target data:  'l gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato el reparto fue bien simple ya que no se necesito l'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UM54Sfe9x80",
        "outputId": "249b6c44-af2a-423a-a9b1-e789092a9bfc"
      },
      "source": [
        "#imprimimos el tensor del dataset\n",
        "print(dataset)\n",
        "#Hyper-Parametros para entrenamiento  de una rede neuronal \n",
        "#   -los datos se agrupan en batch\n",
        "BATCH_SIZE= 64\n",
        "#    -Tamaño de memoria disponible \n",
        "BUFFER_SIZE=10000\n",
        "dataset= dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print (dataset)\n",
        "#En el tensor dataset disponemos los datos de entrenamiento\n",
        "#con agrupamienttos (batches) compuestos de 64 parejas de secuencias \n",
        "#de 100 integers de 64 bits que representan el carácter correspondiente \n",
        "#en el vocabulario."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<MapDataset shapes: ((150,), (150,)), types: (tf.int64, tf.int64)>\n",
            "<BatchDataset shapes: ((64, 150), (64, 150)), types: (tf.int64, tf.int64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ox_5lKZh_qUN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db975a9-5291-4eef-cdd2-2057d596e1d6"
      },
      "source": [
        "#como es un problema de clasificación estándar \n",
        "#para el que debemos definir la función de Lossy el optimizador.\n",
        "def lossy(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "def create_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  #creando el modelo\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                              batch_input_shape=[batch_size, None]),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "                         return_sequences=True,\n",
        "                         stateful=True,\n",
        "                         recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)                               \n",
        "  ])\n",
        "  #En cuanto al optimizador usaremos tf.keras.optimizers.Adam \n",
        "  #con los argumentos por defecto del optimizador Adam. \n",
        "  model.compile(optimizer='adam',\n",
        "              loss=lossy,\n",
        "              metrics=['accuracy'])\n",
        "  return model\n",
        "vocab_size= len(vocab)\n",
        "#dimensiones de los vectores que tendrá la capa.\n",
        "embedding_dim= 256\n",
        "#cantidad de neuronas\n",
        "rnn_units=1024\n",
        "#creamos nuestra red neuronal RNN\n",
        "model=create_model(vocab_size   =vocab_size,\n",
        "                  embedding_dim =embedding_dim,\n",
        "                  rnn_units     =rnn_units,\n",
        "                  batch_size    =BATCH_SIZE)\n",
        "#summary()para visualizar la estructura del modelo\n",
        "model.summary()\n",
        "#resultados=  -La capa LSTM consta más de 5 millones de parametros)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (64, None, 256)           6400      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " dense (Dense)               (64, None, 25)            25625     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,279,001\n",
            "Trainable params: 5,279,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L24WhqeauMWk",
        "outputId": "e4bd03a1-8609-42a5-ba9a-bde0e94c1932"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbeXxiWLF5hN"
      },
      "source": [
        "checkpoint_dir='/content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV5/'\n",
        "checkpoint_prefix= os.path.join(checkpoint_dir,\"cp_{epoch:04d}.ckpt\")\n",
        "\n",
        "\n",
        "cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                               monitor='loss',\n",
        "                                               verbose=1,\n",
        "                                               save_weights_only=True,\n",
        "                                               save_best_only=True,\n",
        "                                               mode='auto')\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l5cnXgLQI7H",
        "outputId": "b8d2a66b-e423-4a9d-e163-3c7d6fef2c63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "EPOCHS=100\n",
        "history=model.fit(dataset, \n",
        "                  epochs=EPOCHS, \n",
        "                  verbose=1,\n",
        "                  callbacks=[cp_callback])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-756226eabe24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                   callbacks=[cp_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m           raise ValueError('Unexpected result of `train_function` '\n\u001b[0m\u001b[1;32m   1228\u001b[0m                            \u001b[0;34m'(Empty logs). Please use '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                            \u001b[0;34m'`Model.compile(..., run_eagerly=True)`, or '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URtG1ZI0L99C"
      },
      "source": [
        "\n",
        "#####4.2a-1 entrenando desde un checkpoint\n",
        "\n",
        "---\n",
        "Desde la carpeta que optamos guardar los checkpoints\n",
        "\n",
        "*   el archivo .data es el archivo que contiene nuestras variables de entrenamiento y vamos a ir tras él.\n",
        "*   el archivo checkpoint, simplemente mantiene un registro de los últimos archivos de punto de control guardados\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o4h9cq8ac68"
      },
      "source": [
        "#creamos un modelo con iguales caracteristicas al 1° modelo\n",
        "model=create_model(vocab_size   =vocab_size,\n",
        "                  embedding_dim =embedding_dim,\n",
        "                  rnn_units     =rnn_units,\n",
        "                  batch_size    =BATCH_SIZE)\n",
        "\n",
        "#buscamos el ultimo checkpoint de entrenamiento\n",
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "print(latest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGZCz4W3lkWa"
      },
      "source": [
        "# cargamos los pesos al nuevo modelo (estos valores tienes una variación de un 10%)\n",
        "model.load_weights(latest)\n",
        "# continuamos el entrenamiento desde el checkpoint en que quedamos\n",
        "history2=model.fit(dataset, \n",
        "                    epochs=50, \n",
        "                    verbose=1,\n",
        "                    callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIkOBKGAP0y-"
      },
      "source": [
        "####P4.2b entrenando con tensorboard (opcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFDzT0NtUpua"
      },
      "source": [
        "#####Activando TENSORBOARD \n",
        "\n",
        "---\n",
        "(DASHBOARD para ver el proceso de entrenamiento)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x20xRy-UwzZ"
      },
      "source": [
        "# You can change the directory name\n",
        "LOG_DIR = 'tb_logs'\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "import os\n",
        "if not os.path.exists(LOG_DIR):\n",
        "  os.makedirs(LOG_DIR)\n",
        "  \n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ1L-Vm1ZrTU"
      },
      "source": [
        "tbCallBack = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, \n",
        "                         histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=BATCH_SIZE,\n",
        "                         write_images=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmC4IO8rg5TV"
      },
      "source": [
        "#####Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcLIbeJjGmDF"
      },
      "source": [
        "\n",
        "#model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)\n",
        "history_TB=model2.fit(dataset, \n",
        "                    epochs=200, \n",
        "                    verbose=1,\n",
        "                    callbacks=[tbCallBack])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnIbqMyqzrWU"
      },
      "source": [
        "##P5. Generando texto nuevo usando la RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vGr7GvUzwxg"
      },
      "source": [
        "#creamos un modelo tomando como base el ultimo checkpoint\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvoSiWWp2_H-"
      },
      "source": [
        "#funcion para generar texto\n",
        "def generate_text(model, start_string):\n",
        "  #definimos cuantos tensores/cantidad de texto generaremos\n",
        "  num_generate=500\n",
        "  #convertimos el texto en números\n",
        "  input_eval=[char2idx[s] for s in start_string]\n",
        "  input_eval= tf.expand_dims (input_eval,0)\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 0.2  #(0.0 a  1) entre más alta la temperatura más creatividad al modelo, pero tambien más errores ortograficos.\n",
        "  model.reset_states() #bucle para generar caracteres, mediante predicciones\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    input_eval= tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append (idx2char[predicted_id])\n",
        "  \n",
        "  return (start_string+ ''.join(text_generated))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFfQ5EiP4ghF"
      },
      "source": [
        "###P5.1 generando texto "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkLdbX724kBy"
      },
      "source": [
        "print(generate_text(model, start_string=u\"la colonia europea\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-3PF45LpJBS"
      },
      "source": [
        "##P6.exportando modelo\n",
        "\n",
        "---\n",
        "Guardamos y Serializamos el Modelo (con esto ya podemos vender nuestro modelo de predicción de texto según lo aprendido por nuestra RNN).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_BJSb-7pL7B"
      },
      "source": [
        "from keras.models import model_from_json\n",
        "import os\n",
        "dir_export= '/content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/Modelos'\n",
        "#dir_export= os.path.join(dir_drive)\n",
        "# Serializamos el modelo en forma JSON\n",
        "model_json = model.to_json()\n",
        "with open(os.path.join(dir_export,'RNN_LasMinasDelReySalomon_json.json'), 'w') as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(os.path.join(dir_export,'RNN_LasMinasDelReySalomon_pesos.hdf5'))\n",
        "model.save(os.path.join(dir_export,'RNN_LasMinasDelReySalomon_model.h5'))\n",
        "print(\"modelo salvado en Drive de google\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfogT546zoDp"
      },
      "source": [
        "##P7.Cargando un modelo serializado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d_bhKoHCE7m"
      },
      "source": [
        "###P7.1 descargamos el modelo usando wget"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R11dLzBzwv0"
      },
      "source": [
        "!wget https://github.com/michelBolivar/Deep_learning/blob/main/Corte2/cuento/cuento_1500/modelRNN_cuentos2_2.h5?raw=true \\\n",
        "      -O modelRNN_cuentos2_2.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKuJocQwCLg1"
      },
      "source": [
        "####P7.1a descargamos el modelo usando PYRIND & URLLIB (OPCIONAL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w_jNNbCAul4"
      },
      "source": [
        "!pip install pyprind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZcueKBiAqRd"
      },
      "source": [
        "def reporthook(count, block_size, total_size):\n",
        "    global start_time\n",
        "    if count == 0:\n",
        "        start_time = time.time()\n",
        "        return\n",
        "    duration = time.time() - start_time\n",
        "    progress_size = int(count * block_size)\n",
        "    speed = progress_size / (1024.**2 * duration)\n",
        "    percent = count * block_size * 100. / total_size\n",
        "    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d segundos transcurrido\" %\n",
        "                    (percent, progress_size / (1024.**2), speed, duration))\n",
        "    sys.stdout.flush()\n",
        "\n",
        "import urllib.request\n",
        "url_github_Model='https://github.com/luisFernandoCastellanosG/Machine_learning/blob/master/DeepLearning/PLN/recurrent_network_RNN/Modelos/RNN_LasMinasDelReySalomon_model.h5?raw=true'\n",
        "urllib.request.urlretrieve(url_github_Model,\n",
        "                           'RNN_LasMinasDelReySalomon_model2.h5', \n",
        "                           reporthook)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lxBCpidCk7b"
      },
      "source": [
        "###P7.2 instanciamos el modelo descargado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dewzz_pW9fFE"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/modelRNN_cuentos2_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFClGoVR2rFG"
      },
      "source": [
        "df2 = pd.read_csv(\"https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/PLN/recurrent_network_RNN/Modelos/data_vocab.csv\")\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyHgx1AP2oz4"
      },
      "source": [
        "#funcion para generar texto\n",
        "def generate_text(model, start_string):\n",
        "  #definimos cuantos tensores/cantidad de texto generaremos\n",
        "  num_generate=500\n",
        "  #convertimos el texto en números\n",
        "  input_eval  = [char2idx[s] for s in start_string]\n",
        "  input_eval  = tf.expand_dims (input_eval,0)\n",
        "  text_generated = []\n",
        "\n",
        "  temperature = 0.2  #(0.0 a  1) entre más alta la temperatura más creatividad al modelo, pero tambien más errores ortograficos.\n",
        "  model.reset_states() #bucle para generar caracteres, mediante predicciones\n",
        "  for i in range(num_generate):\n",
        "    predictions = model(input_eval)\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "    predictions = predictions / temperature\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "    input_eval= tf.expand_dims([predicted_id],0)\n",
        "    text_generated.append (idx2char[predicted_id])\n",
        "  \n",
        "  return (start_string+ ''.join(text_generated))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-rwH5vd0oGc"
      },
      "source": [
        "print(generate_text(new_model, start_string=u\"los fantasmas de \"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}